"""
Tool Workflow Example for Enterprise Knowledge Assistant

This script demonstrates how to integrate tools with workflows in LangGraph,
connecting the basic workflow concepts to tool usage in an enterprise setting.
"""

import os
import sys
from typing import Dict, Any, TypedDict, Literal, List, Union
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from the root
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Load environment variables from .env file
load_dotenv()

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import BaseTool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent

from src.tools.search_tool import get_search_tool

# Define a state for our tool workflow
class ToolWorkflowState(TypedDict):
    """State for our tool workflow."""
    query: str
    context: Dict[str, Any]
    messages: List[Union[HumanMessage, SystemMessage, AIMessage]]
    tool_results: List[Dict[str, Any]]
    response: str
    next: Literal["analyze_query", "execute_tools", "generate_response", "end"]

def create_analysis_agent():
    """Create an agent for analyzing queries."""
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.3,
        convert_system_message_to_human=True
    )
    
    return model

def create_tool_agent():
    """Create an agent that can use tools."""
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.5,
        convert_system_message_to_human=True
    )
    
    # Get the tools
    tools = [get_search_tool()]
    
    # Create the agent
    agent = create_react_agent(
        model,
        tools,
        prompt="""You are a helpful assistant with access to tools.
Use these tools to answer the user's questions about company information.
Always think step by step about which tool would be most appropriate to use.
""",
        debug=True
    )
    
    return agent

def create_response_agent():
    """Create an agent for generating final responses."""
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.7,
        convert_system_message_to_human=True
    )
    
    return model

def analyze_query(state: ToolWorkflowState) -> ToolWorkflowState:
    """Analyze the user query."""
    print(f"🧠 Analyzing query: {state['query']}")
    
    # Create an analysis agent
    agent = create_analysis_agent()
    
    # Create messages for the agent
    messages = [
        SystemMessage(content="""You are a query analysis assistant.
Your job is to analyze user queries and extract key information.
Format your response as a brief analysis of what the query is asking for."""),
        HumanMessage(content=state["query"])
    ]
    
    # Get the analysis
    response = agent.invoke(messages)
    
    # Update the state
    state["context"]["query_analysis"] = response.content
    state["messages"] = messages + [response]
    state["next"] = "execute_tools"
    
    print(f"📝 Analysis: {response.content}")
    
    return state

def execute_tools(state: ToolWorkflowState) -> ToolWorkflowState:
    """Execute tools to gather information."""
    print(f"🔧 Executing tools to gather information")
    
    # Create a tool agent
    agent = create_tool_agent()
    
    # Create the messages
    messages = [HumanMessage(content=state["query"])]
    
    # Add context from the analysis if available
    if "query_analysis" in state["context"]:
        messages = [
            SystemMessage(content=f"Use this query analysis to help you: {state['context']['query_analysis']}"),
            HumanMessage(content=state["query"])
        ]
    
    # Execute the agent
    agent_result = agent.invoke({"messages": messages})
    
    # Extract the result
    if "messages" in agent_result:
        tool_response = agent_result["messages"][-1].content
    else:
        tool_response = "No response generated by the agent."
    
    # Update the state
    state["tool_results"] = agent_result.get("intermediate_steps", [])
    state["context"]["tool_response"] = tool_response
    state["messages"].append(AIMessage(content=tool_response))
    state["next"] = "generate_response"
    
    print(f"🔍 Tool results collected")
    
    return state

def generate_response(state: ToolWorkflowState) -> ToolWorkflowState:
    """Generate a final response."""
    print(f"💬 Generating final response")
    
    # Create a response agent
    agent = create_response_agent()
    
    # Get the tool response
    tool_response = state["context"].get("tool_response", "")
    query_analysis = state["context"].get("query_analysis", "")
    
    # Create messages for the agent
    messages = [
        SystemMessage(content=f"""You are an Enterprise Knowledge Assistant.
Use the following information to provide a comprehensive, well-formatted response:

Query Analysis:
{query_analysis}

Tool Response:
{tool_response}

Format your response in a professional, helpful manner using markdown."""),
        HumanMessage(content=state["query"])
    ]
    
    # Generate the response
    response = agent.invoke(messages)
    
    # Update the state
    state["response"] = response.content
    state["messages"].append(response)
    state["next"] = "end"
    
    print(f"✅ Response generated")
    
    return state

def create_tool_workflow() -> StateGraph:
    """Create a workflow that integrates tools."""
    # Create a new graph
    workflow = StateGraph(ToolWorkflowState)
    
    # Add nodes to the graph
    workflow.add_node("analyze_query", analyze_query)
    workflow.add_node("execute_tools", execute_tools)
    workflow.add_node("generate_response", generate_response)
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "analyze_query",
        lambda state: state["next"],
        {
            "execute_tools": "execute_tools",
            "generate_response": "generate_response",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "execute_tools",
        lambda state: state["next"],
        {
            "generate_response": "generate_response",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "generate_response",
        lambda state: state["next"],
        {
            "end": END
        }
    )
    
    # Set the entry point
    workflow.set_entry_point("analyze_query")
    
    # Compile the graph
    return workflow.compile()

def main():
    """Run the tool workflow example."""
    print("=" * 50)
    print("Enterprise Knowledge Assistant - Tool Workflow Example")
    print("=" * 50)
    
    # Create the workflow
    workflow = create_tool_workflow()
    
    # Get user input
    query = input("\nEnter your query about company information: ")
    
    # Create the initial state
    state = {
        "query": query,
        "context": {},
        "messages": [],
        "tool_results": [],
        "response": "",
        "next": "analyze_query"
    }
    
    # Process the query
    result = workflow.invoke(state)
    
    # Display the result
    print("\n" + "=" * 50)
    print("Final Response:")
    print(result["response"])
    print("=" * 50)
    
    # Show the tool results
    if result["tool_results"]:
        print("\nTool Execution Steps:")
        for i, step in enumerate(result["tool_results"], 1):
            print(f"\nStep {i}:")
            if "action" in step:
                print(f"Tool: {step['action'].tool}")
                print(f"Input: {step['action'].tool_input}")
            if "observation" in step:
                print(f"Result: {step['observation']}")

if __name__ == "__main__":
    main()
