{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the Enterprise Knowledge Assistant\n",
    "\n",
    "This notebook demonstrates how to use the Enterprise Knowledge Assistant, a production-ready LangGraph application that combines all the concepts covered in the LangGraph mastery curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our environment and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the parent directory to the path so we can import from the root\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify that the GOOGLE_API_KEY is set\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"Warning: GOOGLE_API_KEY is not set. Please set it in the .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Enterprise Knowledge Assistant\n",
    "\n",
    "Now, let's initialize the Enterprise Knowledge Assistant by creating the main workflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import initialize_app\n",
    "\n",
    "# Initialize the application\n",
    "graph = initialize_app()\n",
    "print(\"Enterprise Knowledge Assistant initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a Query\n",
    "\n",
    "Let's process a query through the Enterprise Knowledge Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import process_query\n",
    "\n",
    "# Process a query\n",
    "query = \"What is the company policy on data security?\"\n",
    "result = process_query(graph, query)\n",
    "\n",
    "# Display the response\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"results\" in result and \"final_response\" in result[\"results\"]:\n",
    "    print(f\"Response: {result['results']['final_response']}\")\n",
    "else:\n",
    "    print(\"No response generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Workflow State\n",
    "\n",
    "Let's examine the workflow state to understand how the query was processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Print the results\n",
    "print(\"Results:\")\n",
    "for key, value in result.get(\"results\", {}).items():\n",
    "    if key != \"final_response\":  # We already displayed this\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(json.dumps(value, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Feedback\n",
    "\n",
    "Let's provide feedback on the response, which will be processed by the feedback collection node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a query with feedback\n",
    "query = \"What are the steps to request access to the ERP system?\"\n",
    "context = {\n",
    "    \"feedback\": {\n",
    "        \"rating\": 4,\n",
    "        \"comments\": \"Good response, but could provide more details on the approval process.\"\n",
    "    }\n",
    "}\n",
    "result = process_query(graph, query, context)\n",
    "\n",
    "# Display the response\n",
    "if \"results\" in result and \"final_response\" in result[\"results\"]:\n",
    "    print(f\"Response: {result['results']['final_response']}\")\n",
    "\n",
    "# Check if feedback was processed\n",
    "if \"results\" in result and \"feedback_collection\" in result[\"results\"]:\n",
    "    print(\"\\nFeedback processed:\")\n",
    "    print(json.dumps(result[\"results\"][\"feedback_collection\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Let's see how the system handles errors by simulating an error condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.state import AssistantState, ErrorRecord, ErrorSeverity\n",
    "\n",
    "# Create a state with an error\n",
    "state = AssistantState(\n",
    "    query=\"What is the company policy on data security?\",\n",
    "    context={},\n",
    "    messages=[],\n",
    "    current_node=\"query_understanding\",\n",
    "    results={},\n",
    "    errors=[\n",
    "        ErrorRecord(\n",
    "            message=\"Simulated error for demonstration\",\n",
    "            node=\"query_understanding\",\n",
    "            severity=ErrorSeverity.ERROR,\n",
    "            details={\"query\": \"What is the company policy on data security?\"}\n",
    "        )\n",
    "    ],\n",
    "    metadata={\"recovery_attempts\": 0},\n",
    ")\n",
    "\n",
    "# Process the state through the graph\n",
    "result = graph.invoke(state.model_dump())\n",
    "\n",
    "# Display the error handling results\n",
    "if \"results\" in result and \"error_handling\" in result[\"results\"]:\n",
    "    print(\"Error handling results:\")\n",
    "    print(json.dumps(result[\"results\"][\"error_handling\"], indent=2))\n",
    "    \n",
    "    # Display the user message\n",
    "    print(\"\\nUser message:\")\n",
    "    print(result[\"results\"][\"error_handling\"][\"user_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management\n",
    "\n",
    "Let's examine the conversation history stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graphs.nodes.memory_management import get_conversation_history\n",
    "\n",
    "# Get the conversation history\n",
    "history = get_conversation_history(limit=5)\n",
    "\n",
    "# Display the conversation history\n",
    "print(f\"Found {len(history)} conversation entries in memory:\")\n",
    "for i, entry in enumerate(history, 1):\n",
    "    print(f\"\\nEntry {i}:\")\n",
    "    print(f\"Query: {entry.get('query')}\")\n",
    "    print(f\"Response: {entry.get('response')[:100]}...\" if entry.get('response') else \"No response\")\n",
    "    if entry.get('feedback'):\n",
    "        print(f\"Feedback: Rating {entry['feedback'].get('rating')}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the Enterprise Knowledge Assistant, a production-ready LangGraph application. We covered:\n",
    "\n",
    "1. Initializing the assistant\n",
    "2. Processing queries\n",
    "3. Examining the workflow state\n",
    "4. Providing feedback\n",
    "5. Handling errors\n",
    "6. Managing memory\n",
    "\n",
    "These concepts build on the fundamentals covered in the LangGraph mastery curriculum, showing how they can be applied in a real-world enterprise setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
